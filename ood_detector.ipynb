{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5ca924",
   "metadata": {},
   "source": [
    "Script to generate the OOD detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853b96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "import cleanlab\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from torchvision.models import vgg16_bn\n",
    "from torch.utils.data import DataLoader\n",
    "import utils.data_utils as data_utils\n",
    "import utils.train_utils as train_utils\n",
    "from utils.model_selector import model_selector, free_gpu_memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904079a1",
   "metadata": {},
   "source": [
    "Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119d890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "current_path = \"../RESULTS\"\n",
    "batch_size = 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a3aef",
   "metadata": {},
   "source": [
    "Training data can be downloaded from [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15461242.svg)](https://doi.org/10.5281/zenodo.15461242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050abdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', 'LP', 'NO', 'TC', 'TR', 'VT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330f86e",
   "metadata": {},
   "source": [
    "Create a custom Dataset that loads files during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19cbc32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV\n",
      "LP\n",
      "NO\n",
      "TC\n",
      "TR\n",
      "VT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_labels = {0.0: \"VT\", 1.0: \"LP\", 2.0: \"TR\", 3.0: \"NO\", 4.0: \"AV\", 5.0: \"TC\"}\n",
    "data_dir = []\n",
    "data_dir_path = \"../data\"\n",
    "for folder in os.listdir(data_dir_path):\n",
    "    print(folder)\n",
    "    if folder == \"VT\":\n",
    "        class_ = 0.0\n",
    "        for filename in os.listdir(f\"{data_dir_path}/{folder}\"):\n",
    "            path_ = f\"{data_dir_path}/{folder}/{filename}\"\n",
    "            data_dir.append([class_, path_,filename])\n",
    "    elif folder == \"LP\":\n",
    "        class_ = 1.0\n",
    "        for filename in os.listdir(f\"{data_dir_path}/{folder}\"):\n",
    "            path_ = f\"{data_dir_path}/{folder}/{filename}\"\n",
    "            data_dir.append([class_, path_,filename])\n",
    "    elif folder == \"TR\":\n",
    "        class_ = 2.0\n",
    "        for filename in os.listdir(f\"{data_dir_path}/{folder}\"):\n",
    "            path_ = f\"{data_dir_path}/{folder}/{filename}\"\n",
    "            data_dir.append([class_, path_, filename])\n",
    "    elif folder == \"NO\":\n",
    "        class_ = 3.0\n",
    "        for filename in os.listdir(f\"{data_dir_path}/{folder}\"):\n",
    "            path_ = f\"{data_dir_path}/{folder}/{filename}\"\n",
    "            data_dir.append([class_, path_, filename])\n",
    "    elif folder == \"AV\":\n",
    "        class_ = 4.0\n",
    "        for filename in os.listdir(f\"{data_dir_path}/{folder}\"):\n",
    "            path_ = f\"{data_dir_path}/{folder}/{filename}\"\n",
    "            data_dir.append([class_, path_, filename])\n",
    "    elif folder == \"TC\":\n",
    "        class_ = 5.0\n",
    "        for filename in os.listdir(f\"{data_dir_path}/{folder}\"):\n",
    "            path_ = f\"{data_dir_path}/{folder}/{filename}\"\n",
    "            data_dir.append([class_, path_, filename])\n",
    "data_dir_df = pd.DataFrame(data=data_dir, columns=[\"event_class\", \"path\", \"event_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e42211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_class\n",
      "1.0    1828\n",
      "0.0    1502\n",
      "4.0    1236\n",
      "2.0    1203\n",
      "3.0     985\n",
      "5.0     208\n",
      "Name: count, dtype: int64\n",
      "   event_class                     path    event_name\n",
      "0          4.0     ../data/AV/AV__0.npy     AV__0.npy\n",
      "1          4.0     ../data/AV/AV__1.npy     AV__1.npy\n",
      "2          4.0    ../data/AV/AV__10.npy    AV__10.npy\n",
      "3          4.0   ../data/AV/AV__100.npy   AV__100.npy\n",
      "4          4.0  ../data/AV/AV__1000.npy  AV__1000.npy\n",
      "5          4.0  ../data/AV/AV__1001.npy  AV__1001.npy\n",
      "6          4.0  ../data/AV/AV__1002.npy  AV__1002.npy\n",
      "7          4.0  ../data/AV/AV__1003.npy  AV__1003.npy\n",
      "8          4.0  ../data/AV/AV__1004.npy  AV__1004.npy\n",
      "9          4.0  ../data/AV/AV__1005.npy  AV__1005.npy\n"
     ]
    }
   ],
   "source": [
    "print(data_dir_df.value_counts('event_class'))\n",
    "print(data_dir_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04458dff",
   "metadata": {},
   "source": [
    "Trained models are needed to generate embeddings. Train them first with the model_training notebook or download the weights from: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15461242.svg)](https://doi.org/10.5281/zenodo.15461242). The script expects the weights to be located in \"../RESULTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b9463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../RESULTS/rep2_best_model.pt\n",
      "Loading weights and OOD detector...\n",
      "Model weigths successfully loaded...\n",
      "0 / 1134\n",
      "50 / 1134\n",
      "100 / 1134\n",
      "150 / 1134\n",
      "200 / 1134\n",
      "250 / 1134\n",
      "300 / 1134\n",
      "350 / 1134\n",
      "400 / 1134\n",
      "450 / 1134\n",
      "500 / 1134\n",
      "550 / 1134\n",
      "600 / 1134\n",
      "650 / 1134\n",
      "700 / 1134\n",
      "750 / 1134\n",
      "800 / 1134\n",
      "850 / 1134\n",
      "900 / 1134\n",
      "950 / 1134\n",
      "1000 / 1134\n",
      "1050 / 1134\n",
      "1100 / 1134\n",
      "Fitting OOD estimator based on provided features ...\n"
     ]
    }
   ],
   "source": [
    "feat_size = {1: 8193, 2: 14337, 3: 14337, 4: 25089} # size of the embedding generated for each of the representations\n",
    "for rep in [2]:  #[1, 2, 3, 4]:\n",
    "    weights_path = f\"{current_path}/rep{rep}_best_model.pt\" \n",
    "    print(weights_path)\n",
    "    # Take only ID data (VT, LP, TR)\n",
    "    ID_data = data_dir_df.query(\"event_class<3.0\").reset_index()\n",
    "    ID_dataset = data_utils.CustomImageDataset(ID_data,rep_type=rep)\n",
    "    ID_dataloader = DataLoader(ID_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # Load Model\n",
    "    model_torch = model_selector(f\"rep{rep}\",with_OOD=False,weights_path=weights_path,OOD_path=None)\n",
    "    _ = model_torch.eval()\n",
    "    ID_feats_tensor = torch.empty(1, feat_size[rep])\n",
    "    for idx, out in enumerate(ID_dataloader):\n",
    "        X, y, name = out\n",
    "        feats = model_torch.features(X.to(device))\n",
    "        flatten_feats = feats.view(feats.shape[0], -1).detach().cpu()\n",
    "        feats_and_true_lbl = torch.concat([y.view(-1, 1), flatten_feats], axis=1)\n",
    "        ID_feats_tensor = torch.concat([ID_feats_tensor, feats_and_true_lbl], axis=0)\n",
    "        if idx%50==0:\n",
    "            print(idx, \"/\", len(ID_dataloader))\n",
    "\n",
    "    ood_KNN = OutOfDistribution()\n",
    "    train_ood_features_scores = ood_KNN.fit(features=ID_feats_tensor[1:, 1:])\n",
    "    with open(f'{current_path}/OOD_detector_rep{rep}.pkl', 'wb') as f:\n",
    "        pickle.dump(ood_KNN, f)\n",
    "    free_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad990c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".JVGR_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
